<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Body Segmentation Demo</title>
    <style>
        body {
            margin: 0;
            padding: 20px;
            font-family: Arial, sans-serif;
            background: #f0f0f0;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
            text-align: center;
        }
        
        .video-container {
            position: relative;
            display: inline-block;
            margin: 20px 0;
        }
        
        #video {
            display: none;
        }
        
        #canvas {
            border: 2px solid #333;
            max-width: 100%;
            height: auto;
        }
        
        .controls {
            margin: 20px 0;
        }
        
        button {
            background: #007cba;
            color: white;
            border: none;
            padding: 10px 20px;
            margin: 0 5px;
            cursor: pointer;
            border-radius: 5px;
            font-size: 16px;
        }
        
        button:hover {
            background: #005a8b;
        }
        
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        
        .status {
            margin: 10px 0;
            padding: 10px;
            background: #e8f4f8;
            border-radius: 5px;
            font-weight: bold;
        }
        
        .model-select {
            margin: 10px;
        }
        
        select {
            padding: 5px;
            font-size: 16px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Body Segmentation Demo</h1>
        <p>Based on TensorFlow.js Body Segmentation models</p>
        
        <div class="model-select">
            <label for="modelSelect">Choose Model:</label>
            <select id="modelSelect">
                <option value="MediaPipeSelfieSegmentation">MediaPipe Selfie Segmentation</option>
                <option value="BodyPix">BodyPix</option>
            </select>
        </div>
        
        <div class="controls">
            <button id="startBtn">Start Camera</button>
            <button id="stopBtn" disabled>Stop Camera</button>
        </div>
        
        <div class="status" id="status">Click "Start Camera" to begin</div>
        
        <div class="video-container">
            <video id="video" autoplay muted playsinline width="640" height="480"></video>
            <canvas id="canvas" width="640" height="480"></canvas>
        </div>
    </div>

    <!-- TensorFlow.js Core -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.15.0/dist/tf-core.min.js"></script>
    <!-- TensorFlow.js Converter -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.15.0/dist/tf-converter.min.js"></script>
    <!-- TensorFlow.js WebGL Backend -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.15.0/dist/tf-backend-webgl.min.js"></script>
    <!-- MediaPipe Selfie Segmentation -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation@0.1.1675465747/selfie_segmentation.js"></script>
    <!-- Body Segmentation API -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-segmentation@1.0.2/dist/body-segmentation.min.js"></script>

    <script>
        class BodySegmentationDemo {
            constructor() {
                this.video = document.getElementById('video');
                this.canvas = document.getElementById('canvas');
                this.ctx = this.canvas.getContext('2d');
                this.startBtn = document.getElementById('startBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.modelSelect = document.getElementById('modelSelect');
                this.status = document.getElementById('status');
                
                this.segmenter = null;
                this.isRunning = false;
                this.animationFrame = null;
                
                this.setupEventListeners();
            }
            
            setupEventListeners() {
                this.startBtn.addEventListener('click', () => this.startCamera());
                this.stopBtn.addEventListener('click', () => this.stopCamera());
            }
            
            updateStatus(message) {
                this.status.textContent = message;
                console.log(message);
            }
            
            async startCamera() {
                try {
                    this.updateStatus('Starting camera...');
                    
                    // Get user media
                    const stream = await navigator.mediaDevices.getUserMedia({
                        video: { width: 640, height: 480 }
                    });
                    
                    this.video.srcObject = stream;
                    
                    // Wait for video to load
                    await new Promise((resolve) => {
                        this.video.onloadedmetadata = resolve;
                    });
                    
                    this.updateStatus('Loading AI model...');
                    await this.loadModel();
                    
                    this.isRunning = true;
                    this.startBtn.disabled = true;
                    this.stopBtn.disabled = false;
                    this.modelSelect.disabled = true;
                    
                    this.updateStatus('Running segmentation...');
                    this.processFrame();
                    
                } catch (error) {
                    console.error('Error starting camera:', error);
                    this.updateStatus('Error: ' + error.message);
                }
            }
            
            async loadModel() {
                const modelType = this.modelSelect.value;
                
                try {
                    if (modelType === 'MediaPipeSelfieSegmentation') {
                        this.segmenter = await bodySegmentation.createSegmenter(
                            bodySegmentation.SupportedModels.MediaPipeSelfieSegmentation,
                            {
                                runtime: 'mediapipe',
                                modelType: 'general',
                                solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation'
                            }
                        );
                    } else {
                        this.segmenter = await bodySegmentation.createSegmenter(
                            bodySegmentation.SupportedModels.BodyPix,
                            {
                                architecture: 'MobileNetV1',
                                outputStride: 16,
                                multiplier: 0.75,
                                quantBytes: 2
                            }
                        );
                    }
                    
                    this.updateStatus(`${modelType} model loaded successfully`);
                } catch (error) {
                    console.error('Error loading model:', error);
                    throw new Error(`Failed to load ${modelType} model: ${error.message}`);
                }
            }
            
            async processFrame() {
                if (!this.isRunning || !this.segmenter) return;
                
                try {
                    // Get segmentation
                    const people = await this.segmenter.segmentPeople(this.video, {
                        multiSegmentation: false,
                        segmentBodyParts: false
                    });
                    
                    // Render the result
                    await this.renderSegmentation(people);
                    
                } catch (error) {
                    console.error('Error processing frame:', error);
                    // On error, just show the original video
                    this.ctx.drawImage(this.video, 0, 0, this.canvas.width, this.canvas.height);
                }
                
                if (this.isRunning) {
                    this.animationFrame = requestAnimationFrame(() => this.processFrame());
                }
            }
            
            async renderSegmentation(people) {
                // Clear canvas
                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
                
                if (people && people.length > 0) {
                    // Create a green background
                    this.ctx.fillStyle = '#00ff00';
                    this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
                    
                    // Get the mask and convert to ImageData
                    const foregroundColor = {r: 0, g: 0, b: 0, a: 0};
                    const backgroundColor = {r: 0, g: 255, b: 0, a: 255};
                    const drawContour = false;
                    const foregroundThreshold = 0.5;
                    
                    const mask = await bodySegmentation.toBinaryMask(
                        people, 
                        foregroundColor, 
                        backgroundColor, 
                        drawContour, 
                        foregroundThreshold
                    );
                    
                    // Draw the original video
                    this.ctx.drawImage(this.video, 0, 0, this.canvas.width, this.canvas.height);
                    
                    // Apply the mask
                    const opacity = 0.7;
                    const maskBlurAmount = 0;
                    
                    await bodySegmentation.drawMask(
                        this.canvas,
                        this.video,
                        mask,
                        opacity,
                        maskBlurAmount
                    );
                } else {
                    // No people detected, just show the video
                    this.ctx.drawImage(this.video, 0, 0, this.canvas.width, this.canvas.height);
                }
            }
            
            stopCamera() {
                this.isRunning = false;
                
                if (this.animationFrame) {
                    cancelAnimationFrame(this.animationFrame);
                }
                
                if (this.video.srcObject) {
                    const tracks = this.video.srcObject.getTracks();
                    tracks.forEach(track => track.stop());
                    this.video.srcObject = null;
                }
                
                if (this.segmenter) {
                    this.segmenter.dispose();
                    this.segmenter = null;
                }
                
                this.startBtn.disabled = false;
                this.stopBtn.disabled = true;
                this.modelSelect.disabled = false;
                
                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
                this.updateStatus('Camera stopped');
            }
        }
        
        // Initialize the demo when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new BodySegmentationDemo();
        });
    </script>
</body>
</html> 